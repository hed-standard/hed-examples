{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analyze the channels for the Baseline Driving\n",
    "\n",
    "This notebook assumes that a JSON dictionary called `originalChannels.json`\n",
    "has been created in the `/code` subdirectory of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Log output:\n",
      "bcit_baseline_driving_05_analyze_channels_log: Level None\n",
      "sub-01_ses-01_task-DriveWithSpeedChange_run-1_eeg.set:\n",
      "\t[ This key has 50 files with the same 74 channels]\n",
      "\t[ The channels are ['Fp1', 'AF7', 'AF3', 'F1', 'F3', 'F5', 'F7', 'FT7', 'FC5', 'FC3', 'FC1', 'C1', 'C3', 'C5', 'T7', 'TP7', 'CP5', 'CP3', 'CP1', 'P1', 'P3', 'P5', 'P7', 'P9', 'PO7', 'PO3', 'O1', 'Iz', 'Oz', 'POz', 'Pz', 'CPz', 'Fpz', 'Fp2', 'AF8', 'AF4', 'AFz', 'Fz', 'F2', 'F4', 'F6', 'F8', 'FT8', 'FC6', 'FC4', 'FC2', 'FCz', 'Cz', 'C2', 'C4', 'C6', 'T8', 'TP8', 'CP6', 'CP4', 'CP2', 'P2', 'P4', 'P6', 'P8', 'P10', 'PO8', 'PO4', 'O2', 'EXG1', 'EXG2', 'EXG3', 'EXG4', 'EXG5', 'EXG6', 'LN', 'ANG', 'SP', 'SD']]\n",
      "sub-100_ses-01_task-DriveWithSpeedChange_run-1_eeg.set:\n",
      "\t[ This key has 81 files with the same 266 channels]\n",
      "\t[ The channels are ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27', 'A28', 'A29', 'A30', 'A31', 'A32', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B9', 'B10', 'B11', 'B12', 'B13', 'B14', 'B15', 'B16', 'B17', 'B18', 'B19', 'B20', 'B21', 'B22', 'B23', 'B24', 'B25', 'B26', 'B27', 'B28', 'B29', 'B30', 'B31', 'B32', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26', 'C27', 'C28', 'C29', 'C30', 'C31', 'C32', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'D16', 'D17', 'D18', 'D19', 'D20', 'D21', 'D22', 'D23', 'D24', 'D25', 'D26', 'D27', 'D28', 'D29', 'D30', 'D31', 'D32', 'E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10', 'E11', 'E12', 'E13', 'E14', 'E15', 'E16', 'E17', 'E18', 'E19', 'E20', 'E21', 'E22', 'E23', 'E24', 'E25', 'E26', 'E27', 'E28', 'E29', 'E30', 'E31', 'E32', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10', 'F11', 'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20', 'F21', 'F22', 'F23', 'F24', 'F25', 'F26', 'F27', 'F28', 'F29', 'F30', 'F31', 'F32', 'G1', 'G2', 'G3', 'G4', 'G5', 'G6', 'G7', 'G8', 'G9', 'G10', 'G11', 'G12', 'G13', 'G14', 'G15', 'G16', 'G17', 'G18', 'G19', 'G20', 'G21', 'G22', 'G23', 'G24', 'G25', 'G26', 'G27', 'G28', 'G29', 'G30', 'G31', 'G32', 'H1', 'H2', 'H3', 'H4', 'H5', 'H6', 'H7', 'H8', 'H9', 'H10', 'H11', 'H12', 'H13', 'H14', 'H15', 'H16', 'H17', 'H18', 'H19', 'H20', 'H21', 'H22', 'H23', 'H24', 'H25', 'H26', 'H27', 'H28', 'H29', 'H30', 'H31', 'H32', 'EXG1', 'EXG2', 'EXG3', 'EXG4', 'EXG5', 'EXG6', 'LN', 'ANG', 'SP', 'SD']]\n",
      "Overall:\n",
      "\t[ Dataset has 316 unique channels]\n",
      "\t[ {'F26', 'E26', 'D31', 'F6', 'A29', 'A18', 'F30', 'D10', 'G23', 'G17', 'H3', 'E30', 'A5', 'F9', 'E12', 'C10', 'E31', 'H5', 'E20', 'G32', 'G25', 'C30', 'G22', 'G26', 'B4', 'D11', 'G2', 'D4', 'G18', 'B13', 'C15', 'H12', 'G5', 'B24', 'C16', 'O1', 'CP6', 'F5', 'F4', 'F22', 'H13', 'B28', 'P6', 'A8', 'CP4', 'C12', 'H7', 'Iz', 'T8', 'G24', 'G9', 'F21', 'G16', 'F7', 'P9', 'D13', 'A17', 'E24', 'F27', 'G12', 'CP5', 'Pz', 'B8', 'F11', 'F32', 'G10', 'H10', 'E15', 'A13', 'A27', 'T7', 'C5', 'A28', 'B12', 'EXG4', 'D18', 'FC5', 'F3', 'H30', 'H21', 'H27', 'H1', 'A2', 'B3', 'A6', 'H9', 'FC6', 'B11', 'D17', 'E4', 'G13', 'D15', 'A32', 'G7', 'H24', 'E9', 'D8', 'Fp2', 'G6', 'Fz', 'B27', 'C26', 'H4', 'A31', 'D21', 'B22', 'D28', 'SD', 'F8', 'H8', 'SP', 'E21', 'H19', 'D1', 'G11', 'D25', 'E7', 'F15', 'B9', 'D24', 'Oz', 'A19', 'E23', 'E14', 'LN', 'EXG1', 'C4', 'C20', 'E10', 'B31', 'C17', 'D27', 'H26', 'P2', 'P3', 'E5', 'E32', 'P5', 'C29', 'D23', 'G28', 'P7', 'Fp1', 'TP7', 'EXG2', 'A23', 'G29', 'CP3', 'C6', 'B14', 'G4', 'G8', 'CP1', 'F17', 'D19', 'B21', 'AF4', 'C31', 'CP2', 'A15', 'F2', 'F1', 'C2', 'F13', 'H16', 'F31', 'B23', 'B29', 'H22', 'C22', 'C32', 'H11', 'C3', 'B32', 'B7', 'C25', 'D26', 'Cz', 'PO7', 'E2', 'C9', 'D29', 'B26', 'G20', 'FC3', 'D30', 'P1', 'Fpz', 'P8', 'H23', 'H20', 'FT8', 'P4', 'FC4', 'A10', 'D2', 'D5', 'G31', 'E25', 'G21', 'A26', 'E13', 'E29', 'B1', 'A12', 'D9', 'D14', 'E1', 'H2', 'D20', 'FC1', 'E6', 'G3', 'C24', 'A7', 'F16', 'G15', 'EXG6', 'H29', 'B17', 'F18', 'C7', 'PO3', 'FCz', 'E17', 'G19', 'B20', 'AF8', 'H25', 'E8', 'P10', 'C27', 'B18', 'C8', 'F25', 'CPz', 'F12', 'H15', 'EXG5', 'H17', 'A4', 'AF7', 'AFz', 'B16', 'C28', 'D3', 'E27', 'E19', 'A1', 'C14', 'C21', 'C13', 'A25', 'G1', 'A9', 'B6', 'B25', 'F20', 'PO4', 'F14', 'D16', 'E11', 'F24', 'E18', 'C11', 'G30', 'A20', 'G27', 'H31', 'AF3', 'PO8', 'B19', 'ANG', 'B30', 'A24', 'D22', 'E22', 'C19', 'A3', 'A14', 'H6', 'O2', 'FT7', 'H14', 'B10', 'D12', 'E16', 'EXG3', 'D6', 'B5', 'E3', 'D32', 'A21', 'FC2', 'B2', 'C23', 'F29', 'A11', 'POz', 'F19', 'G14', 'B15', 'E28', 'F28', 'C1', 'A22', 'A16', 'D7', 'F10', 'F23', 'TP8', 'A30', 'H32', 'H28', 'C18', 'H18'}]\n",
      "\n",
      "\n",
      "ERROR Summary:\n",
      "bcit_baseline_driving_05_analyze_channels_log: Level ERROR\n",
      "sub-01_ses-01_task-DriveWithSpeedChange_run-1_eeg.set:\n",
      "sub-100_ses-01_task-DriveWithSpeedChange_run-1_eeg.set:\n",
      "Overall:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import json\n",
    "from hed.tools import HedLogger\n",
    "from hed.util import get_file_list\n",
    "\n",
    "# Variables to set for the specific dataset\n",
    "bids_root_path = 's:/bcit/BaselineDrivingWorkingPhaseTwo'\n",
    "exclude_dirs = ['sourcedata', 'stimuli', 'code']\n",
    "entities = ('sub', 'ses', 'run')\n",
    "log_name = 'bcit_baseline_driving_05_analyze_channels_log'\n",
    "channel_file = os.path.realpath(os.path.join(bids_root_path, \"code/channelsOriginal.json\"))\n",
    "\n",
    "# Set up the logger\n",
    "log_file_name = f\"code/curation_logs/{log_name}.txt\"\n",
    "logger = HedLogger(name=log_name)\n",
    "\n",
    "# Load the channels file\n",
    "with open(channel_file, 'r') as fp:\n",
    "    channel_info = json.load(fp)\n",
    "\n",
    "# Make the file list and dictionary for _events\n",
    "eeg_files = get_file_list(bids_root_path, extensions=[\".set\"], name_suffix=\"_eeg\", exclude_dirs=exclude_dirs)\n",
    "\n",
    "# Create the dictionaries of channels\n",
    "key_list = list(channel_info.keys())\n",
    "unique_dict = {}\n",
    "name_dict = {}\n",
    "for file_key, item in channel_info.items():\n",
    "    search_key = None\n",
    "    for skey in name_dict.keys():\n",
    "        if item == channel_info[skey]:\n",
    "            search_key = skey\n",
    "            break\n",
    "    if search_key:\n",
    "        search_values = name_dict[search_key]\n",
    "        name_dict[search_key].append(file_key)\n",
    "    else:\n",
    "        name_dict[file_key] = [file_key]\n",
    "\n",
    "# Now check the order of the elements in the list:\n",
    "all_channels = set\n",
    "for file_key, file_list in name_dict.items():\n",
    "    logger.add(file_key, f\"This key has {len(file_list)} files with the same {len(channel_info[file_key])} channels\")\n",
    "    logger.add(file_key, f\"The channels are {str(channel_info[file_key])}\")\n",
    "\n",
    "\n",
    "key_list = list(name_dict.keys())\n",
    "union_channels = set()\n",
    "inter_channels = set(channel_info[key_list[0]])\n",
    "for file_key in key_list:\n",
    "    union_channels = union_channels.union(set(channel_info[file_key]))\n",
    "    inter_channels = inter_channels.intersection(set(channel_info[file_key]))\n",
    "logger.add(\"Overall\", f\"Dataset has {len(union_channels)} unique channels\")\n",
    "logger.add(\"Overall\", f\"{str(union_channels)}\")\n",
    "\n",
    "# Output and save the log\n",
    "log_string = \"\\n\\nLog output:\\n\" + logger.get_log_string()\n",
    "error_string = \"\\n\\nERROR Summary:\\n\" + logger.get_log_string(level=\"ERROR\")\n",
    "print(log_string)\n",
    "print(error_string)\n",
    "save_path = os.path.join(bids_root_path, log_file_name)\n",
    "with open(save_path, \"w\") as fp:\n",
    "    fp.write(f\"{log_file_name} {datetime.datetime.now()}\\n\")\n",
    "    fp.write(log_string)\n",
    "    fp.write(error_string)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Create the template for the dataset\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}